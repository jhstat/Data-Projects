
================================================================================
SECOM MANUFACTURING DEFECT DETECTION: ML INTERPRETABILITY PROJECT
================================================================================
Date: 2026-01-17
Duration: 4 hours
Dataset: SECOM (Semiconductor Manufacturing)

================================================================================
1. DATASET SUMMARY
================================================================================
Original features: 590
After cleaning: 460 (dropped 8 sparse, 122 constant)
Training samples: 1,253 (7.34% defect rate)
Test samples: 314 (3.82% defect rate)

Key challenge: Extreme dimensionality (460 features, 92 defects)
                → ~5 defect samples per feature

================================================================================
2. TEMPORAL ANALYSIS
================================================================================
Finding: Significant batch effects detected (p < 0.0001)
  - Defect rate varied from 1.3% to 15.3% across production periods
  - No significant day-of-week or time-of-day patterns (p > 0.15)
  
Decision: Time-based train/test split (not random)
  - Respects temporal ordering
  - Tests generalization to future production regime
  
Impact: Test set has half the defect rate of training (distribution shift)

================================================================================
3. DATA CLEANING STRATEGY
================================================================================
Step 1: Dropped 8 features with >80% missing (not correlated with target)
Step 2: Imputed remaining missing with median (fitted on train only)
Step 3: Dropped 122 constant features (zero variance)
Step 4: Verified all features are continuous (no categorical encoding needed)

Rejected: Correlation-based feature dropping
Rationale: Tree models handle correlation naturally; risk losing complementary
           information (e.g., inlet/outlet temperature difference)

================================================================================
4. MODEL PERFORMANCE
================================================================================
Model: LightGBM with balanced class weights (12.6x penalty for defects)

Results:
  Train AUC: 0.970
  Test AUC:  0.735
  Gap:       0.235 (significant overfitting)
  
  Test Confusion Matrix (threshold=0.5):
                  Predicted
                Pass    Fail
    Actual Pass  288     14
    Actual Fail   11      1    ← Only 8% recall

Cross-Validation (5-fold time-series):
  F1 Score: 0.115 ± 0.100
  
Diagnosis:
  ✗ Severe overfitting (curse of dimensionality: 460 features, 92 defects)
  ✗ Distribution shift (train 7.34% → test 3.82% defect rate)
  ✗ Test set too small (only 12 defects → high metric variance)

================================================================================
5. SHAP INTERPRETATION
================================================================================
Top 5 Most Important Features (by mean |SHAP|):
  1. Feature 59:  0.0669 (dominant)
  2. Feature 468: 0.0447
  3. Feature 111: 0.0425
  4. Feature 79:  0.0387
  5. Feature 195: 0.0218

Key Insight: Feature importance highly concentrated
  → Top feature is 46% more important than #2
  → Suggests most features are noise

Example: Actual Defect (Sample 58)
  Predicted: 0.473 (borderline)
  True: Fail
  
  SHAP Explanation:
    Feature 111: +0.070 (toward defect)
    Feature 468: -0.059 (toward pass)  ← Conflicting signals
    Feature 79:  -0.049 (toward pass)
  
  → Model uncertainty due to contradictory feature signals

================================================================================
6. KEY TAKEAWAYS
================================================================================
✓ Successfully built end-to-end interpretable ML pipeline
✓ Applied rigorous temporal analysis and data cleaning
✓ Diagnosed root causes of poor performance (not just "model didn't work")
✓ Used SHAP to identify which features model relies on

✗ Model performance is poor (F1 0.115) due to:
  1. Curse of dimensionality (5 defects per feature)
  2. Temporal distribution shift (7.34% → 3.82%)
  3. Noisy sensor data with contradictory signals

================================================================================
7. NEXT STEPS (Production Deployment)
================================================================================
Short-term (1-2 weeks):
  1. Feature selection: Reduce 460 → 50-100 using domain knowledge + SHAP
  2. Threshold optimization: Tune for business costs (missed defect vs. false alarm)
  3. Collect more defect samples: Current 92 is insufficient for 460 features

Long-term (1-3 months):
  1. Domain collaboration: Identify which sensors are meaningful vs. noise
  2. Feature engineering: Create interaction features (sensor differences, ratios)
  3. Ensemble methods: Combine models trained on different temporal regimes
  4. Active learning: Focus labeling on borderline cases
  5. Continuous monitoring: Retrain as defect patterns evolve

================================================================================
8. INTERVIEW TALKING POINTS
================================================================================
Strengths demonstrated:
  ✓ Statistical rigor (chi-square tests, correlation analysis)
  ✓ Domain awareness (manufacturing context, temporal patterns)
  ✓ Model interpretability (SHAP analysis, communicating insights)
  ✓ Intellectual honesty (acknowledging limitations, diagnosing root causes)
  ✓ Production thinking (time-based validation, avoiding data leakage)

Key insight:
  "The value isn't in achieving perfect metrics on a 4-hour project—it's in
   demonstrating a principled approach to interpretable ML and being able to
   diagnose why a model struggles. SECOM is notoriously difficult, and my
   results align with published literature. The analysis provides clear
   guidance for next steps rather than claiming premature success."

================================================================================
ARTIFACTS GENERATED
================================================================================
1. shap_importance_bar.png      - Top 20 feature importance
2. shap_summary_plot.png         - Feature impact visualization
3. shap_waterfall_defect_58.png  - Individual prediction explanation
4. temporal_defect_rate.png      - Temporal analysis (if created earlier)
================================================================================
